{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**This file represents the final Pytorch implementation for training and evaluating our final model**"
      ],
      "metadata": {
        "id": "FUag3Llz8KP-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import"
      ],
      "metadata": {
        "id": "psVODpo48SDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import optim\n",
        "from torch import nn\n",
        "from torchvision import transforms, models\n",
        "from tqdm import tqdm\n",
        "from torchmetrics import Accuracy, Precision, Recall\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from MultiStreamResNet import MultiStreamResNet #Import from other file\n",
        "from MultiModalDataset import get_dataloaders #Import from other file"
      ],
      "metadata": {
        "id": "62rgoOuW8LUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "General configuratio, reproducibility and device, like previous files"
      ],
      "metadata": {
        "id": "u1QfF75BDne9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.0005 # Lower Learning rate\n",
        "NUM_EPOCHS = 20\n",
        "IMG_SIZE = 128\n",
        "VAL_SPLIT_RATIO = 0.20\n",
        "MODEL_SAVE_PATH = 'multimodal_resnet_fusion.pth'\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {DEVICE}\")"
      ],
      "metadata": {
        "id": "dfcv6NfKDx01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "General path"
      ],
      "metadata": {
        "id": "AejZyqWlEDWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = r'C:\\Users\\franc\\Desktop\\data science\\PRIMO ANNO\\python\\final project'\n",
        "spec_train_dir = os.path.join(base_dir, r'Dataset_Spectrogram\\train')\n",
        "spec_test_dir = os.path.join(base_dir, r'Dataset_Spectrogram\\test')\n",
        "wave_train_dir = os.path.join(base_dir, r'Dataset_Waveform\\train')\n",
        "wave_test_dir = os.path.join(base_dir, r'Dataset_Waveform\\test')"
      ],
      "metadata": {
        "id": "rygZesUIEBLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data transforms: same for each stream"
      ],
      "metadata": {
        "id": "kcw8mRyjEGS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "standard_transforms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "gbB8x0NbELKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to evaluate each single epoch"
      ],
      "metadata": {
        "id": "ImVmk4ktENiQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_epoch(model, dataloader, device):\n",
        "    model.eval()\n",
        "    acc_metric = Accuracy(task=\"multiclass\", num_classes=NUM_CLASSES).to(device)\n",
        "    with torch.no_grad():\n",
        "        for spec_data, wave_data, targets in dataloader:\n",
        "            spec_data, wave_data, targets = spec_data.to(device), wave_data.to(device), targets.to(device)\n",
        "            outputs = model(spec_data, wave_data) # Doppia chiamata\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            acc_metric.update(preds, targets)\n",
        "    return acc_metric.compute().item()"
      ],
      "metadata": {
        "id": "bmXO1f8eESqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test on the model"
      ],
      "metadata": {
        "id": "JQ6F2XX2EYTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, dataloader, device, class_names):\n",
        "    acc = Accuracy(task=\"multiclass\", num_classes=NUM_CLASSES).to(device)\n",
        "    precision = Precision(task=\"multiclass\", num_classes=NUM_CLASSES, average='macro', zero_division=0).to(device)\n",
        "    recall = Recall(task=\"multiclass\", num_classes=NUM_CLASSES, average='macro', zero_division=0).to(device)\n",
        "\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    print(\"\\n--- Starting final evaluation ---\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for spec_data, wave_data, labels in tqdm(dataloader, desc=\"Testing Multi-Stream\"):\n",
        "\n",
        "            spec_data = spec_data.to(device)\n",
        "            wave_data = wave_data.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(spec_data, wave_data)\n",
        "\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            acc.update(preds, labels)\n",
        "            precision.update(preds, labels)\n",
        "            recall.update(preds, labels)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    test_accuracy = acc.compute().item()\n",
        "    test_precision = precision.compute().item()\n",
        "    test_recall = recall.compute().item()\n",
        "\n",
        "    # Stampa dei risultati\n",
        "    print(\"\\n--- Results ---\")\n",
        "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "    print(f\"Test Macro Precision: {test_precision:.4f}\")\n",
        "    print(f\"Test Macro Recall: {test_recall:.4f}\")\n",
        "\n",
        "    print(\"\\n--- Classification Report (Test Set) ---\")\n",
        "    print(classification_report(all_labels, all_preds, target_names=class_names, zero_division=0))\n",
        "\n",
        "    #Confusion matrix\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel('Prediction')\n",
        "    plt.ylabel('Truth')\n",
        "    plt.title('Confusion matrix')\n",
        "    plt.show()\n",
        "\n",
        "    return test_accuracy"
      ],
      "metadata": {
        "id": "dWrV5TvwEavc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final exectution"
      ],
      "metadata": {
        "id": "rpfbO5qFEzvL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    set_seed(42)\n",
        "    train_loader, validation_loader, test_loader, class_names = get_dataloaders(\n",
        "        spec_train_dir=spec_train_dir, wave_train_dir=wave_train_dir,\n",
        "        spec_test_dir=spec_test_dir, wave_test_dir=wave_test_dir,\n",
        "        spec_transforms=standard_transforms, wave_transforms=standard_transforms,\n",
        "        batch_size=BATCH_SIZE, val_split_ratio=VAL_SPLIT_RATIO\n",
        "    )\n",
        "\n",
        "    model = MultiStreamResNet(NUM_CLASSES, DEVICE)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "    best_val_acc = 0.0\n",
        "\n",
        "    print(\"\\n--- Starting training ---\")\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        model.train()\n",
        "        epoch_loss = 0.0\n",
        "\n",
        "        for spec_data, wave_data, targets in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{NUM_EPOCHS}\"):\n",
        "            spec_data, wave_data, targets = spec_data.to(DEVICE), wave_data.to(DEVICE), targets.to(DEVICE)\n",
        "\n",
        "            scores = model(spec_data, wave_data)\n",
        "            loss = criterion(scores, targets)\n",
        "\n",
        "            optimizer.zero_grad(); loss.backward(); optimizer.step();\n",
        "            epoch_loss += loss.item() * targets.size(0)\n",
        "\n",
        "        total_train_loss = epoch_loss / len(train_loader.dataset)\n",
        "        val_acc = validate_epoch(model, validation_loader, DEVICE)\n",
        "\n",
        "        print(f\"Loss: {total_train_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
        "            print(f\" New record! Val Acc: {best_val_acc:.4f} <<<\")\n",
        "\n",
        "    model.load_state_dict(torch.load(MODEL_SAVE_PATH, map_location=DEVICE))\n",
        "    test_model(model, test_loader, DEVICE, class_names)\n",
        "    print(\"\\nTraining DONE.\")"
      ],
      "metadata": {
        "id": "mpVuRSF0E1qY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import"
      ],
      "metadata": {
        "id": "0QWGPpJouz3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import optim\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms, models\n",
        "from tqdm import tqdm\n",
        "from torchmetrics import Accuracy, Precision, Recall\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import random"
      ],
      "metadata": {
        "id": "dNCA_h2zyxUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "General configuration: defining hyperparameters for the training process"
      ],
      "metadata": {
        "id": "yDmeb6k6yyTv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_CLASSES = 10 #n. of genres\n",
        "BATCH_SIZE = 60 #number of samples per training iteration\n",
        "LEARNING_RATE = 0.001 #rate at which model weights are updated\n",
        "NUM_EPOCHS = 20\n",
        "IMG_SIZE = 128  #target dim for image resizing\n",
        "VAL_SPLIT_RATIO = 0.20 #20% of the training data will be used for validation"
      ],
      "metadata": {
        "id": "r9tzUksjy2Sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GPU if available"
      ],
      "metadata": {
        "id": "Vab25hSHz1hm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {DEVICE}\")"
      ],
      "metadata": {
        "id": "Cchz9mAry607"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To ensure that initialization of weights and data processing is deterministic across multple runs"
      ],
      "metadata": {
        "id": "5YyVXt6vz3Wr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "-5zy4t9Dy7Vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining paths"
      ],
      "metadata": {
        "id": "dlPPaWti0HeX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_dir = r'C:\\Users\\giann\\Desktop\\universita\\magistrale\\FUNDATIONS OF DATA SCIENCE\\progetto finale\\Data\\Dataset_Spectrogram\\train'\n",
        "test_data_dir = r'C:\\Users\\giann\\Desktop\\universita\\magistrale\\FUNDATIONS OF DATA SCIENCE\\progetto finale\\Data\\Dataset_Spectrogram\\test'"
      ],
      "metadata": {
        "id": "Pz0Zis03y_6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a pipeline that standardizes input images: first resizes all input images to 128 pixels, then concerts the image into a tensor and scales pixel values from [0,255] to [0, 1]. The value in Normalize are standard values of ImageNet."
      ],
      "metadata": {
        "id": "E3bjoL6A0LXt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "h0lpH1TTzDNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining network: pre trained Resnet 18, using Transfer Learning.\n",
        "\n",
        "1.   Future extractor: The initial layers of ResNet18 (convolution blocks) are kept exactly as they were trained on ImageNet. These layers are excellent at recognizing general image features\n",
        "2.   Specialized Classifier: This is modified and trainend specifically on our spectrogram data. This allows the model to learn our new classes starting from the general features learned from ImageNet Dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "paQai02K00H2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_resnet_model(num_classes, device):\n",
        "    print(\"Downloading and configuring ResNet18...\")\n",
        "    weights = models.ResNet18_Weights.DEFAULT\n",
        "    model = models.resnet18(weights=weights)\n",
        "\n",
        "    # Modify the final Fully Connected layer\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Linear(num_ftrs, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.4),\n",
        "        nn.Linear(256, num_classes)\n",
        "    )\n",
        "    return model.to(device)"
      ],
      "metadata": {
        "id": "X1xazaZB1Gai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function used to evaluate model's performance for a single epoch"
      ],
      "metadata": {
        "id": "GJHqjLBx1HUR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_epoch(model, dataloader, device):\n",
        "    model.eval()\n",
        "    acc_metric = Accuracy(task=\"multiclass\", num_classes=NUM_CLASSES).to(device)\n",
        "    with torch.no_grad():\n",
        "        for data, targets in dataloader:\n",
        "            data, targets = data.to(device), targets.to(device)\n",
        "            outputs = model(data)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            acc_metric.update(preds, targets)\n",
        "    return acc_metric.compute().item()"
      ],
      "metadata": {
        "id": "fD-YF09Q1LV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function runs the model on the dedicated test set to measure its performance.\n"
      ],
      "metadata": {
        "id": "oBaJrqiD1L8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, dataloader, device, class_names):\n",
        "    acc = Accuracy(task=\"multiclass\", num_classes=NUM_CLASSES).to(device)\n",
        "    precision = Precision(task=\"multiclass\", num_classes=NUM_CLASSES, average='macro').to(device)\n",
        "    recall = Recall(task=\"multiclass\", num_classes=NUM_CLASSES, average='macro').to(device)\n",
        "\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(dataloader, desc=\"Testing\"):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            acc.update(preds, labels)\n",
        "            precision.update(preds, labels)\n",
        "            recall.update(preds, labels)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    print(f\"\\nTest Accuracy: {acc.compute():.4f}\")\n",
        "    print(f\"Test Macro Precision: {precision.compute():.4f}\")\n",
        "    print(\"\\nClassification Report (Test Set):\")\n",
        "    print(classification_report(all_labels, all_preds, target_names=class_names))\n",
        "\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.show()\n",
        "\n",
        "    return acc.compute()"
      ],
      "metadata": {
        "id": "C_pRAjxI1QSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main execution section: load and prepare the data to train the CNN and running the final evaluation"
      ],
      "metadata": {
        "id": "UDEESAF_1TYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    set_seed(42)\n",
        "    # 1. LOAD DATA\n",
        "    full_train_dataset = datasets.ImageFolder(root=train_data_dir, transform=data_transforms)\n",
        "    test_dataset = datasets.ImageFolder(root=test_data_dir, transform=data_transforms)\n",
        "\n",
        "    val_size = int(VAL_SPLIT_RATIO * len(full_train_dataset))\n",
        "    train_size = len(full_train_dataset) - val_size\n",
        "\n",
        "    train_dataset, validation_dataset = random_split(full_train_dataset, [train_size, val_size])\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "    validation_loader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "\n",
        "    class_names = full_train_dataset.classes\n",
        "    print(f\"Dataset Training: {len(train_dataset)} | Validation: {len(validation_dataset)} | Test: {len(test_dataset)}\")\n",
        "\n",
        "    # 2. INITIALIZATION\n",
        "    model = get_resnet_model(NUM_CLASSES, DEVICE)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    # 3. TRAINING LOOP\n",
        "    print(\"\\n--- START TRAINING RESNET18 ---\")\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        model.train()\n",
        "        epoch_loss = 0.0\n",
        "\n",
        "        for data, targets in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{NUM_EPOCHS}\"):\n",
        "            data, targets = data.to(DEVICE), targets.to(DEVICE)\n",
        "\n",
        "            # Forward\n",
        "            scores = model(data)\n",
        "            loss = criterion(scores, targets)\n",
        "\n",
        "            # Backward\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item() * data.size(0)\n",
        "\n",
        "        total_train_loss = epoch_loss / len(train_dataset)\n",
        "        val_acc = validate_epoch(model, validation_loader, DEVICE)\n",
        "\n",
        "        print(f\"Loss: {total_train_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "    # 4. FINAL EVALUATION\n",
        "    test_model(model, test_loader, DEVICE, class_names)"
      ],
      "metadata": {
        "id": "gQua6aRQw8Nl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}